{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed210cf-5d3c-4966-8ffb-f4bf158b0bfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df42e09-f1b7-49bb-82c4-847193707333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wand\n",
      "  Downloading Wand-0.6.10-py2.py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wand\n",
      "Successfully installed wand-0.6.10\n"
     ]
    }
   ],
   "source": [
    "! pip install wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42a71dd-f260-465e-8709-4a5ac7b839e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling /opt/homebrew/Cellar/imagemagick/7.1.0-51... (805 files, 30.8MB)\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/imagemagick/6/manifests/6.9.12-\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/imagemagick/6/blobs/sha256:3681\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring imagemagick@6--6.9.12-66.arm64_monterey.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "imagemagick@6 is keg-only, which means it was not symlinked into /opt/homebrew,\n",
      "because this is an alternate version of another formula.\n",
      "\n",
      "If you need to have imagemagick@6 first in your PATH, run:\n",
      "  echo 'export PATH=\"/opt/homebrew/opt/imagemagick@6/bin:$PATH\"' >> ~/.zshrc\n",
      "\n",
      "For compilers to find imagemagick@6 you may need to set:\n",
      "  export LDFLAGS=\"-L/opt/homebrew/opt/imagemagick@6/lib\"\n",
      "  export CPPFLAGS=\"-I/opt/homebrew/opt/imagemagick@6/include\"\n",
      "\n",
      "For pkg-config to find imagemagick@6 you may need to set:\n",
      "  export PKG_CONFIG_PATH=\"/opt/homebrew/opt/imagemagick@6/lib/pkgconfig\"\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "ðŸº  /opt/homebrew/Cellar/imagemagick@6/6.9.12-66: 767 files, 27.3MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup imagemagick@6`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "\u001b[31mError:\u001b[0m No such keg: /opt/homebrew/Cellar/imagemagick\n",
      "Linking /opt/homebrew/Cellar/imagemagick@6/6.9.12-66... 76 symlinks created.\n",
      "\n",
      "If you need to have this software first in your PATH instead consider running:\n",
      "  echo 'export PATH=\"/opt/homebrew/opt/imagemagick@6/bin:$PATH\"' >> ~/.zshrc\n"
     ]
    }
   ],
   "source": [
    "! brew uninstall imagemagick\n",
    "! brew install imagemagick@6\n",
    "! brew unlink imagemagick\n",
    "! brew link imagemagick@6 --force\n",
    "! echo 'export MAGICK_HOME=\"/usr/local/opt/imagemagick@6/lib\"' >> ~/.bash_profile\n",
    "! echo 'export PATH=\"/usr/local/opt/imagemagick@6/bin:$PATH\"' >> ~/.bash_profile\n",
    "\n",
    "! source ~/.bash_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccb8c1-2c79-4b1a-bdad-7d9309b27055",
   "metadata": {},
   "outputs": [],
   "source": [
    "! convert -list font"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a45893-a50f-4ae0-b3a4-03f2422717e6",
   "metadata": {},
   "source": [
    "## Font Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "03556180-1ae2-4974-a09c-b92260b69278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from wand.color import Color\n",
    "from wand.image import Image\n",
    "from wand.drawing import Drawing\n",
    "from wand.compat import nested\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1876bdad-d6a1-4510-b3c6-c8c3f8bf3b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charatcters \n",
    "language = 'abcdefghijklmnopqrstuvwxyz'\n",
    "language_upper = language.upper()\n",
    "language += language_upper\n",
    "language += '0123456789'\n",
    "\n",
    "assert len(language) == 26 * 2 + 10 \n",
    "language = language_upper\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "5ecd375e-a338-4d4e-a601-532a0697fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonts\n",
    "handwritten_fonts = ['Herculanum', 'Annai MN', 'Bradley Hand', 'Brush Script MT', 'Chalkboard',\n",
    "             'Comic Sans MS', 'Luminary', 'Noteworthy', 'Papyrus', 'Party LET', 'Savoye LET', \n",
    "             'Sign Painter', 'Skia', 'Snell Roundhand', 'Times New Roman', 'Trattatello', 'Zapfino']\n",
    "typed_fonts = ['Arial', 'Arial Black', 'Arial Narrow', 'Arial Rounded MT Bold', 'Copperplate', 'Courier New', 'Helvetica',\n",
    "              'Impact', 'Lucinda Grande', 'Microsoft Sans Serif', 'Tahoma', 'Verdana', 'Menlo', 'Didot', 'Copperplate', 'Avenir', 'Futura']\n",
    "\n",
    "fonts = handwritten_fonts + typed_fonts \n",
    "# fonts = ['Chalkboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "adc5894d-e450-40e5-84a8-5743725bb216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution\n",
    "width=200\n",
    "height=200\n",
    "font_size=100\n",
    "background = Color('white')\n",
    "foreground=Color('rgb(0, 0, 0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "72195ecd-aa71-4bd8-a415-c87cc5e8a57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ba027f7c-4c24-4724-b708-4df1c21fa239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(language, language_upper):\n",
    "    for c in language:\n",
    "        if c in language_upper:\n",
    "            if os.path.exists(f'{c}{c}'):\n",
    "                shutil.rmtree(f'{c}{c}')\n",
    "        else:\n",
    "            if os.path.exists(c):\n",
    "                shutil.rmtree(f'{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c205e0c8-330e-4456-8af0-ddbb03829d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(fonts, language, language_upper, width=200, height=200, font_size=100, background=Color('white'), foreground=Color('rgb(0,0,0)')):\n",
    "    for f in tqdm(fonts):\n",
    "        for c in language:\n",
    "            if c in language_upper:\n",
    "                if not os.path.exists(f'{c}{c}'):\n",
    "                    os.mkdir(f'{c}{c}')\n",
    "                filename = os.path.join(f'{c}{c}', f'{f}.png')\n",
    "            else:\n",
    "                if not os.path.exists(c):\n",
    "                    os.mkdir(f'{c}')\n",
    "                filename = os.path.join(f'{c}', f'{f}.png')\n",
    "\n",
    "            with Drawing() as draw:\n",
    "                with Image(width=width, height=height, background=background) as img:\n",
    "                    draw.font_family = f\n",
    "                    draw.font_size = font_size\n",
    "                    draw.push()\n",
    "                    draw.fill_color = foreground\n",
    "                    draw.text(0,int(img.height/2), c)\n",
    "                    draw.pop()\n",
    "                    draw(img)\n",
    "                    if os.path.exists(filename):\n",
    "                        os.unlink(filename)\n",
    "                    img.save(filename='tmp.png')\n",
    "\n",
    "                    img = cv2.imread('tmp.png')\n",
    "\n",
    "                    os.unlink('tmp.png')\n",
    "                    ys, xs = np.where(np.all(img == (0, 0, 0), axis=-1))\n",
    "                    \n",
    "                    if len(ys) > 0 and len(xs) > 0:\n",
    "                        cropped = img[min(ys):max(ys)+1, min(xs):max(xs)+1]\n",
    "                        cv2.imwrite(filename, cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8fb5a737-7951-4716-b586-6f65cfe0d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:04<00:00,  7.07it/s]\n"
     ]
    }
   ],
   "source": [
    "generate(fonts, language, language_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b447e5-99ab-4fa0-95be-573f3958db17",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b2269-bf65-4e2a-b3ab-5e8d77948f85",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d7309709-8572-4c8b-aab1-016da8d810fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,2)\n",
    "*a, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "49da5048-ea5c-4cf6-917e-0b23d07adc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show(*img):\n",
    "    for i in img:\n",
    "        plt.imshow(i, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "def show_rgb(*img):\n",
    "    for i in img:\n",
    "        plt.imshow(i, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "def read(path):\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def read_rgb(path):\n",
    "    return cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "def bin(img, bins=10, min_diff=10):\n",
    "    count, division = np.histogram(img, bins)\n",
    "    diff_series = pd.Series(count).diff()\n",
    "    \n",
    "    first_histogram_reduction_index = diff_series[(diff_series < 0) & (np.abs(diff_series) > min_diff)].index[0]\n",
    "    threshold = division[first_histogram_reduction_index+1]\n",
    "        \n",
    "    _, img = cv2.threshold(img,threshold,255,cv2.THRESH_BINARY)\n",
    "    return img\n",
    "\n",
    "def bin2(img):\n",
    "    return cv2.threshold(img, 0, 255, cv2.THRESH_BINARY +cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def neg(img):\n",
    "    return 255 - img\n",
    "\n",
    "def redraw_contours(img, thickness=16): \n",
    "    # Find contours and redraw\n",
    "    contours, hierarchy = cv2.findContours(image=img, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "                                      \n",
    "    # draw contours on the original image\n",
    "    image_copy = img.copy()\n",
    "    cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(255, 255, 255), thickness=thickness, lineType=cv2.LINE_AA)\n",
    "    return image_copy\n",
    "\n",
    "def components(img, min_area=800):\n",
    "    # Connected components\n",
    "    output = cv2.connectedComponentsWithStats(img, 4, cv2.CV_32S)\n",
    "    num_letters = output[0]\n",
    "    letters = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    letter_imgs = []\n",
    "    ## Sort letters + area check\n",
    "    for l in range(1, num_letters):\n",
    "        minx = stats[l, cv2.CC_STAT_LEFT]\n",
    "        maxx = stats[l, cv2.CC_STAT_WIDTH] + minx\n",
    "        miny = stats[l, cv2.CC_STAT_TOP] \n",
    "        maxy = stats[l, cv2.CC_STAT_HEIGHT] + miny\n",
    "        area = stats[l, cv2.CC_STAT_AREA]\n",
    "        if area < min_area:\n",
    "            continue\n",
    "\n",
    "        cropped_img = img[miny:maxy+1, minx: maxx+1].copy()\n",
    "        \n",
    "        # Add negatives directly \n",
    "        letter_imgs.append((neg(cropped_img), minx, maxx, miny, maxy))\n",
    "\n",
    "    # Detect spaces and newlines\n",
    "    sorted_imgs_y = sorted(letter_imgs, \n",
    "       key=lambda x: x[3])\n",
    "\n",
    "    rectangles = sorted_imgs_y.copy()\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    rows = defaultdict(list)\n",
    "    row_id = 0\n",
    "    while len(rectangles) > 0:\n",
    "        r = rectangles[0]\n",
    "        rows[row_id].append(r)\n",
    "        ctr_y = (r[3] + r[4])/2\n",
    "        rectangles.remove(r)\n",
    "        \n",
    "        to_remove = []\n",
    "        for (img, minx, maxx, miny, maxy) in rectangles:\n",
    "            # if central y line goes through letter box\n",
    "            if ctr_y >= miny and ctr_y <= maxy:\n",
    "                rows[row_id].append((img, minx, maxx, miny, maxy))\n",
    "                to_remove.append((img, minx, maxx, miny, maxy))\n",
    "        \n",
    "        for rem in to_remove:\n",
    "            rectangles.remove(rem)\n",
    "            \n",
    "        row_id+=1\n",
    "    \n",
    "    final_result = []\n",
    "    # for y in text\n",
    "    for row in range(row_id):\n",
    "        line = []\n",
    "        # Search for spaces\n",
    "        sorted_imgs_x = sorted(rows[row], \n",
    "           key=lambda x: x[1])\n",
    "        \n",
    "        # for char in line\n",
    "        word = []\n",
    "        for i in range(0, len(sorted_imgs_x)-1):\n",
    "            xmax_first = sorted_imgs_x[i][2]\n",
    "            xmin_second = sorted_imgs_x[i+1][1]\n",
    "\n",
    "            prev_letter_width = sorted_imgs_x[i][2] - sorted_imgs_x[i][1]\n",
    "            dist = (xmin_second - xmax_first)\n",
    "            \n",
    "            word.append(sorted_imgs_x[i])\n",
    "            if dist > prev_letter_width:\n",
    "                line.append(word)\n",
    "                word = []\n",
    "        \n",
    "        # Assume no space at end of line\n",
    "        word.append(sorted_imgs_x[-1])\n",
    "        line.append(word)\n",
    "        final_result.append(line)\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "def gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def resize(img, size=(100, 100)):\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def erode(img, it=1):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    return cv2.erode(img, kernel, iterations=it)\n",
    "\n",
    "def dilate(img, it=1):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    return cv2.dilate(img, kernel, iterations=it)\n",
    "\n",
    "def blur(x):\n",
    "    return cv2.GaussianBlur(x, (3, 3), cv2.BORDER_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "f5e19144-d3a2-4982-ac87-384560fdd696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_2(path, show_steps=False):\n",
    "    x = read(path)\n",
    "    y = cv2.Laplacian(x, cv2.CV_16S, ksize=3)\n",
    "\n",
    "    # Binarize\n",
    "    z = y.copy()\n",
    "    z[z > 127] = 255\n",
    "    z[z <= 127] = 0\n",
    "    \n",
    "    # Thicken letters\n",
    "    q = dilate(z, it=3).astype(np.uint8)\n",
    "    \n",
    "    # Find components\n",
    "    lines = components(q)\n",
    "\n",
    "    if show_steps:\n",
    "        show(x)\n",
    "        show(y)\n",
    "        show(z)\n",
    "        show(q)\n",
    "        for line in lines:\n",
    "            for word in line:\n",
    "                for c in word:\n",
    "                    show(c[0])\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "f955559d-c7ba-41dc-a2a8-b7c441d7ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMI \n",
      "IHAGE \n",
      "PRQQESSLNG \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = ocr_nn('multiline.png')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "5570067c-508e-4773-b606-28275ab02827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL SHTEWS \n",
      "ESHTA BOB \n",
      "RALZFLLO \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = ocr_nn('total.png', show_steps=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f15cd-29c7-4bc6-a67d-ec56e588650f",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "12a2cfd2-0f55-4411-8b95-8cc88d1716e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9f8e0119-2c38-40a5-86ef-344dfdca9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(train_images, train_labels, depth=2):\n",
    "    res_images = []\n",
    "    res_labels = []\n",
    "    for i in range(train_images.shape[0]):\n",
    "        img = train_images[i]\n",
    "        l = train_labels[i]\n",
    "        for it in range(0, depth):\n",
    "            img_x = erode(img, it=it)\n",
    "            res_images.append(img_x)\n",
    "            res_labels.append(l)\n",
    "        for it in range(0, depth):\n",
    "            img_x = dilate(img, it=it)\n",
    "            res_images.append(img_x)\n",
    "            res_labels.append(l)\n",
    "    return np.stack(res_images),np.array(res_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "96142a8a-ef40-46b3-af7a-b4fcc2a74cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                589888    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 26)                1690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 647,322\n",
      "Trainable params: 647,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 2.1334 - accuracy: 0.4225\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 0.7349 - accuracy: 0.8138\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 2s 91ms/step - loss: 0.3416 - accuracy: 0.9079\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 0.1576 - accuracy: 0.9572\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 0.0888 - accuracy: 0.9741\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 0.0541 - accuracy: 0.9834\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 0.0415 - accuracy: 0.9878\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 0.0271 - accuracy: 0.9927\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 0.0140 - accuracy: 0.9971\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0090 - accuracy: 0.9980\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0124 - accuracy: 0.9953\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 2s 89ms/step - loss: 0.0160 - accuracy: 0.9965\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 2s 90ms/step - loss: 0.0127 - accuracy: 0.9971\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0170 - accuracy: 0.9959\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 2s 86ms/step - loss: 0.0260 - accuracy: 0.9930\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0109 - accuracy: 0.9974\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0115 - accuracy: 0.9959\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 2s 86ms/step - loss: 0.0225 - accuracy: 0.9948\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0099 - accuracy: 0.9980\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 0.0100 - accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "## Augment Data\n",
    "size = 64\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(size, size, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(language)))\n",
    "model.summary()\n",
    "\n",
    "import glob\n",
    "\n",
    "image_paths = sorted(glob.glob(\"*/*.png\"))\n",
    "train_labels = np.array(list(range(26)))\n",
    "classes = sorted(set([i[:i.index('/')] for i in image_paths]))\n",
    "classes_fmap = dict(zip(classes, train_labels))\n",
    "classes_imap = dict(zip(train_labels, classes))\n",
    "\n",
    "train_images = [bin(resize(read(x), size=(size, size)))//255 for x in image_paths]\n",
    "train_labels = np.stack([classes_fmap[i[:i.index('/')]] for i in image_paths])\n",
    "train_images = np.stack(train_images)\n",
    "\n",
    "# Augment images \n",
    "train_images_augmented, train_labels_augmented = augment(train_images, train_labels, depth=2)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images_augmented, train_labels_augmented, \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "19f53fbc-c2b0-4b46-9c4f-277bc64b495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nn_augmented(letter_img, inference_size=(size, size), _filter='.png'):\n",
    "    # Add dilation to inference\n",
    "    letter_imgs_augmented = [dilate(letter_img, it=i) for i in range(3)]\n",
    "    letter_imgs_augmented += [erode(letter_img, it=i) for i in range(3)]\n",
    "    \n",
    "    characters = []\n",
    "    for i, letter_img in enumerate(letter_imgs_augmented):\n",
    "        letter_img_res = bin(resize(letter_img, inference_size))//255\n",
    "        letter_img_tensor = np.stack([letter_img_res])\n",
    "\n",
    "        results = model.predict(letter_img_tensor, verbose=False)\n",
    "        char_idx = np.argmax(results)\n",
    "        character = classes_imap[char_idx][0]\n",
    "        characters.append({'char': character, 'dilate_it': i, 'result': np.max(results)})\n",
    "        \n",
    "    characters = pd.DataFrame(characters)\n",
    "    return characters['char'].mode().values[0]\n",
    "\n",
    "def classify_nn(letter_img, inference_size=(size, size), _filter='.png'):\n",
    "    letter_img_res = bin(resize(letter_img, inference_size))//255\n",
    "    letter_img_tensor = np.stack([letter_img_res])\n",
    "    \n",
    "    results = model.predict(letter_img_tensor, verbose=False)\n",
    "    char_idx = np.argmax(results)\n",
    "    character = classes_imap[char_idx][0]\n",
    "    return character, results\n",
    "\n",
    "def ocr(path, show_steps, class_fn):\n",
    "    lines = pipeline_2(path, show_steps=show_steps)\n",
    "    text = ''\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            for c, *_ in word:\n",
    "                char = class_fn(c)[0]\n",
    "                text += char\n",
    "            text += ' '\n",
    "        text += '\\n'\n",
    "    return text\n",
    "\n",
    "def ocr_nn(path, show_steps=False):\n",
    "    return ocr(path, show_steps, classify_nn)\n",
    "    \n",
    "    \n",
    "def ocr_nn_augmented(path, show_steps=False):\n",
    "    return ocr(path, show_steps, classify_nn_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fe5dd-93f6-4fa8-9dbb-8e9b599fa62e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Tests NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "8af7710b-8219-4aca-beb2-eed7b7aa36a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('C',\n",
       "   array([[-7.9650264e+00, -1.3834951e+00,  1.2596487e+01,  5.6434002e+00,\n",
       "            6.2750216e+00, -1.0346209e+01, -3.0045459e+00, -6.4410105e+00,\n",
       "            6.4317684e+00,  5.4019656e+00, -6.6936736e+00, -1.5903983e-02,\n",
       "           -5.3574519e+00,  4.6499548e+00,  1.2555685e+01, -3.0026367e+00,\n",
       "            1.1905471e+00, -5.1748452e+00,  2.7976406e+00,  3.0307505e+00,\n",
       "           -4.7817626e+00, -1.6235720e+01, -1.7238410e+00,  3.0715261e+00,\n",
       "           -1.3852016e+00, -1.3062192e+00]], dtype=float32)),\n",
       "  ('L',\n",
       "   array([[ -8.455614 ,  -0.8418528,  14.129976 ,   6.329447 ,   5.1831527,\n",
       "           -18.671293 ,   3.747546 ,  -5.011556 ,  10.150172 ,   7.6068316,\n",
       "             7.6509523,  23.275553 ,  -7.660453 ,  -7.0412903,   6.889268 ,\n",
       "            -2.4809484,  14.086274 ,  -6.427495 ,   1.5482782,  -9.092689 ,\n",
       "            -3.589717 , -11.280183 , -12.544739 ,   2.9061317,   1.3964843,\n",
       "            13.260579 ]], dtype=float32)),\n",
       "  ('F',\n",
       "   array([[  2.9253075,  -5.151885 , -21.826681 , -14.243878 ,  -9.462668 ,\n",
       "            12.334279 , -11.932606 ,   9.851508 , -10.876666 , -22.615559 ,\n",
       "            -0.711402 ,  -7.254745 ,  -5.1343584,  -4.720485 ,  -2.7075026,\n",
       "             2.9963148,  -8.450517 ,   8.486924 ,  -6.924816 ,  -7.3230624,\n",
       "           -21.755028 ,  -0.5994163,  -4.4744177,   6.2871003,  -3.3516195,\n",
       "            -1.6161705]], dtype=float32)),\n",
       "  ('L',\n",
       "   array([[ -8.455614 ,  -0.8418528,  14.129976 ,   6.329447 ,   5.1831527,\n",
       "           -18.671293 ,   3.747546 ,  -5.011556 ,  10.150172 ,   7.6068316,\n",
       "             7.6509523,  23.275553 ,  -7.660453 ,  -7.0412903,   6.889268 ,\n",
       "            -2.4809484,  14.086274 ,  -6.427495 ,   1.5482782,  -9.092689 ,\n",
       "            -3.589717 , -11.280183 , -12.544739 ,   2.9061317,   1.3964843,\n",
       "            13.260579 ]], dtype=float32))],\n",
       " ' ',\n",
       " '\\n']"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_nn('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ffa8d33f-a7cc-446d-a75b-68d9e1289801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAN\n",
      "FRI\n",
      "DIGLTAL\n",
      "TACTICNL\n",
      "OCR\n",
      "TEST\n",
      "PROCESSLNN\n",
      "TEAN\n",
      "FMI\n",
      "DIGLTAL\n",
      "TACTICNL\n",
      "OCR\n",
      "TEST\n",
      "PROCESSINN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<function __main__.ocr_nn(path, show_steps=False, return_dfs=False)>: 0.8461538461538461,\n",
       " <function __main__.ocr_nn_augmented(path, show_steps=False, return_dfs=False)>: 0.8974358974358975}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "# fns = [ocr, ocr_nn, ocr_nn_augmented]\n",
    "fns = [ocr_nn, ocr_nn_augmented]\n",
    "tests = [x for x in os.listdir('.') if x.endswith('.png') or x.endswith('.jpg')]\n",
    "for fn in fns:\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    \n",
    "    for t in tests:\n",
    "        label = t[:t.index('.')].upper()\n",
    "        num_total += len(label)\n",
    "\n",
    "        result = ''.join(fn(t))\n",
    "        for i in range(min(len(label), len(result))):\n",
    "            if label[i] == result[i]:\n",
    "                num_correct+=1\n",
    "        print(result)\n",
    "        \n",
    "    results[fn] = num_correct/num_total\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5815141b-c378-49f4-96e4-d4e3f7975d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arial Unicode.ttf\n"
     ]
    }
   ],
   "source": [
    "! ls -R /Library/Fonts | grep ttf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbb43c-2b21-4a05-a62d-a6f29fc418fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1b7a0951-6bb7-4f2c-be23-ec5272d36462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'F', 'S', 'T']\n",
      "['O', 'C', 'R']\n",
      "['T', 'A', 'C', 'T', 'T', 'C', 'A', 'L']\n",
      "['Q', 'T', 'C', 'T', 'T', 'A', 'L']\n",
      "['T', 'E', 'A', 'A']\n",
      "['P', 'X', 'O', 'C', 'C', 'S', 'S', 'X', 'X', 'A']\n",
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_total = 0\n",
    "\n",
    "for t in ['test.png', 'ocr.png', 'tactical.png', 'digital.png', 'team.png', 'processing.png']:\n",
    "    label = t[:t.index('.')].upper()\n",
    "    num_total += len(label)\n",
    "    \n",
    "    result = ''.join(ocr(t))    \n",
    "    for i in range(len(label)):\n",
    "        if label[i] == result[i]:\n",
    "            num_correct+=1\n",
    "        \n",
    "    print(ocr(t))\n",
    "print('Accuracy:', num_correct/num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c88e363b-e1c8-4449-8852-93479730f054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'F', 'S', 'T']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "915f276e-346f-45b4-b45e-66f210b0fe43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'A', 'C', 'T', 'T', 'C', 'A', 'L']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr('tactical.png', show_steps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "10487d47-e8e9-41ad-a517-a2ada886dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'I', 'C', 'I', 'T', 'A', 'L']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr('digital.png', show_steps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4091e482-3d94-4920-b36c-c7938fb9082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'C', 'R']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr('ocr.png', show_steps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aa94c185-83e8-4fa8-9522-43fad12d7887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'E', 'A', 'A']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr('team.png', show_steps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c77dadc6-8777-42da-959d-37a62a9a5a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F', 'R', 'D', 'C', 'F', 'S', 'S', 'I', 'X', 'A']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr('processing.png', show_steps=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
